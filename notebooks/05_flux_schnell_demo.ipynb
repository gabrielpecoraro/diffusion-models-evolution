{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. FLUX.1-schnell --- 12B Parameters on a MacBook\n",
    "\n",
    "**Running the Largest Open-Source Diffusion Model via GGUF Quantization**\n",
    "\n",
    "FLUX.1-schnell (Black Forest Labs, Aug 2024) is a 12-billion parameter rectified flow transformer\n",
    "that generates high-quality images in just **4 inference steps**. Under normal float16 precision\n",
    "it requires ~24 GB of VRAM, putting it out of reach for most consumer hardware.\n",
    "\n",
    "In this notebook we run FLUX.1-schnell on a **16 GB Apple Silicon Mac** by applying GGUF 4-bit\n",
    "quantization to the transformer backbone and combining it with CPU offloading. This is the\n",
    "centerpiece demo of the project --- proving that state-of-the-art diffusion models can run\n",
    "locally on modest hardware with the right optimization strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why GGUF Quantization?\n",
    "\n",
    "| Component | Full Precision | With GGUF Q4_K_S |\n",
    "|-----------|---------------|-------------------|\n",
    "| FLUX transformer (12B params) | ~24 GB (float16) | ~6.8 GB (4-bit) |\n",
    "| Text encoders (CLIP + T5) | ~2 GB | ~2 GB (unchanged) |\n",
    "| VAE decoder | ~0.3 GB | ~0.3 GB (unchanged) |\n",
    "| **Total peak** | **~26 GB** | **~10 GB** |\n",
    "\n",
    "Key ideas:\n",
    "\n",
    "- The FLUX.1 transformer has 12B parameters = ~24 GB in float16\n",
    "- Our Mac has 16 GB unified memory --- not enough for full precision\n",
    "- **GGUF Q4_K_S** quantizes weights to 4 bits with super-block scaling, reducing the\n",
    "  transformer to ~6.8 GB\n",
    "- Combined with `enable_model_cpu_offload()` and float16 for the text encoders / VAE,\n",
    "  the full pipeline fits in ~10 GB peak\n",
    "- **Trade-off**: Slight quality reduction vs full precision, but still impressive for\n",
    "  consumer hardware and more than good enough for prototyping and experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Ensure project root is on the path so we can import config/ and models/\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"\"))\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from config.default import DiffusionConfig\n",
    "from models.memory_utils import setup_mps_environment, clear_memory, log_memory_usage\n",
    "from models.pipeline_factory import load_pipeline, generate_image\n",
    "from models.prompt_bank import BENCHMARK_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DiffusionConfig(\n",
    "    model_name=\"flux-schnell\",\n",
    "    quantization=\"Q4_K_S\",\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=0.0,  # FLUX schnell uses guidance distillation, no CFG needed\n",
    "    height=512,\n",
    "    width=512,\n",
    "    seed=42,\n",
    "    dtype=\"float16\",\n",
    "    enable_cpu_offload=True,\n",
    ")\n",
    "\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"Quantization: {config.quantization} (4-bit GGUF)\")\n",
    "print(f\"Steps: {config.num_inference_steps} (guidance distilled!)\")\n",
    "print(f\"Guidance Scale: {config.guidance_scale} (no CFG needed)\")\n",
    "print(f\"Resolution: {config.width}x{config.height}\")\n",
    "print(f\"CPU offload: {config.enable_cpu_offload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Only 4 Steps?\n",
    "\n",
    "Traditional diffusion models use **Classifier-Free Guidance (CFG)** at every denoising step.\n",
    "This means the model runs **twice** per step --- once with the text condition and once without\n",
    "--- then blends the results. A typical workflow looks like:\n",
    "\n",
    "```\n",
    "Traditional: 50 steps x 2 forward passes = 100 forward passes total\n",
    "```\n",
    "\n",
    "FLUX.1-schnell changes the game in two ways:\n",
    "\n",
    "1. **Guidance Distillation**: The model was trained to produce CFG-quality results in a\n",
    "   **single forward pass** per step. The \"knowledge\" of classifier-free guidance has been\n",
    "   distilled directly into the model weights during training. That is why we set\n",
    "   `guidance_scale=0.0` --- no CFG is needed at inference time.\n",
    "\n",
    "2. **Flow Matching with Straight Trajectories**: Instead of the curved denoising paths of\n",
    "   traditional DDPM/DDIM schedulers, flow matching learns nearly straight trajectories\n",
    "   from noise to data. Straighter paths need fewer discretization steps to follow accurately.\n",
    "\n",
    "Combined, this gives us:\n",
    "\n",
    "```\n",
    "FLUX.1-schnell: 4 steps x 1 forward pass = 4 forward passes total\n",
    "```\n",
    "\n",
    "That is a **25x reduction** in neural network evaluations compared to a traditional 50-step\n",
    "CFG pipeline --- and the image quality remains remarkably competitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_memory_usage(\"before loading\")\n",
    "print(\"Loading FLUX.1-schnell with GGUF Q4_K_S quantization...\")\n",
    "print(\"(First run will download ~7GB of model weights)\")\n",
    "\n",
    "pipe = load_pipeline(config)\n",
    "\n",
    "log_memory_usage(\"after loading FLUX.1-schnell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A corgi holding a wooden sign that reads 'FLUX.1'\"\n",
    "config.prompt = prompt\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Generating with just {config.num_inference_steps} steps...\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "image = generate_image(pipe, config)\n",
    "elapsed = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"Generation time: {elapsed:.1f}s\")\n",
    "log_memory_usage(\"after generation\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(image)\n",
    "ax.set_title(\n",
    "    f\"FLUX.1-schnell | {config.num_inference_steps} steps | {elapsed:.1f}s | GGUF Q4_K_S\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "os.makedirs(os.path.join(\"..\", \"outputs\", \"flux_schnell\"), exist_ok=True)\n",
    "image.save(os.path.join(\"..\", \"outputs\", \"flux_schnell\", \"corgi_sign.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Count Comparison\n",
    "\n",
    "How does image quality change with different step counts? Since FLUX.1-schnell is optimized\n",
    "for 4 steps via guidance distillation, we compare **1, 2, 4, and 8** steps to see the\n",
    "diminishing-returns curve. At 1 step the model barely resolves structure; by 4 steps quality\n",
    "is excellent; 8 steps offers marginal improvement at the cost of doubled inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_counts = [1, 2, 4, 8]\n",
    "step_images = []\n",
    "step_times = []\n",
    "\n",
    "test_prompt = \"A photorealistic astronaut riding a white horse on Mars, cinematic lighting\"\n",
    "\n",
    "for steps in step_counts:\n",
    "    config.prompt = test_prompt\n",
    "    config.num_inference_steps = steps\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    img = generate_image(pipe, config)\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    step_images.append(img)\n",
    "    step_times.append(elapsed)\n",
    "    print(f\"  {steps} steps: {elapsed:.1f}s\")\n",
    "\n",
    "# Reset to default\n",
    "config.num_inference_steps = 4\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for ax, img, steps, t in zip(axes, step_images, step_counts, step_times):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\n",
    "        f\"{steps} step{'s' if steps > 1 else ''} | {t:.1f}s\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"FLUX.1-schnell: Quality vs Step Count\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Suite\n",
    "\n",
    "Now we run all 5 benchmark prompts from `models.prompt_bank`. These are the same prompts\n",
    "used in the SD3 Medium notebook, enabling a fair head-to-head comparison later in Notebook 06.\n",
    "Each prompt targets a different capability: text rendering, photorealism, spatial reasoning,\n",
    "artistic style transfer, and compositional complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_inference_steps = 4\n",
    "config.guidance_scale = 0.0\n",
    "\n",
    "images = []\n",
    "times = []\n",
    "\n",
    "for i, ps in enumerate(BENCHMARK_PROMPTS):\n",
    "    print(f\"[{i+1}/{len(BENCHMARK_PROMPTS)}] {ps.category}: {ps.prompt[:60]}...\")\n",
    "    config.prompt = ps.prompt\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    img = generate_image(pipe, config)\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    images.append(img)\n",
    "    times.append(elapsed)\n",
    "    print(f\"  Done in {elapsed:.1f}s\")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(20, 4))\n",
    "for ax, img, ps, t in zip(axes, images, BENCHMARK_PROMPTS, times):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{ps.category}\\n{t:.1f}s\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"FLUX.1-schnell --- Benchmark Suite (512x512, 4 steps, GGUF Q4_K_S)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for img, ps in zip(images, BENCHMARK_PROMPTS):\n",
    "    img.save(os.path.join(\"..\", \"outputs\", \"flux_schnell\", f\"{ps.name}.png\"))\n",
    "print(f\"Saved {len(images)} images to outputs/flux_schnell/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FLUX.1-schnell Performance (16GB Apple Silicon, GGUF Q4_K_S)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Prompt':<20} {'Category':<18} {'Time (s)':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for ps, t in zip(BENCHMARK_PROMPTS, times):\n",
    "    print(f\"{ps.name:<20} {ps.category:<18} {t:<10.1f}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Average':<20} {'':<18} {sum(times)/len(times):<10.1f}\")\n",
    "print(f\"\\nResolution: {config.width}x{config.height}\")\n",
    "print(f\"Steps: {config.num_inference_steps}\")\n",
    "print(f\"Quantization: {config.quantization}\")\n",
    "\n",
    "log_memory_usage(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe\n",
    "clear_memory()\n",
    "log_memory_usage(\"after cleanup\")\n",
    "print(\"Pipeline unloaded. Memory cleared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "- **Speed**: 4 steps is remarkably fast --- this is what guidance distillation combined with\n",
    "  flow matching enables. Each step is a single forward pass through the 12B transformer,\n",
    "  with no duplicate CFG evaluation.\n",
    "\n",
    "- **Text rendering**: FLUX.1 excels at rendering legible text within images, a known\n",
    "  strength of the MMDiT (Multimodal Diffusion Transformer) architecture and its deep\n",
    "  cross-attention between text and image tokens.\n",
    "\n",
    "- **GGUF trade-off**: Q4_K_S quantization has minimal visible quality impact at 512x512.\n",
    "  The super-block scaling in Q4_K_S preserves important weight distributions better than\n",
    "  naive 4-bit quantization.\n",
    "\n",
    "- **Memory**: Peak usage stays around ~10 GB thanks to quantization + CPU offloading,\n",
    "  comfortably within the 16 GB unified memory budget of entry-level Apple Silicon Macs.\n",
    "\n",
    "- **Next**: Notebook 06 puts SD3 Medium and FLUX.1-schnell head-to-head on the same\n",
    "  benchmark prompts, comparing quality, speed, and memory usage side by side."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
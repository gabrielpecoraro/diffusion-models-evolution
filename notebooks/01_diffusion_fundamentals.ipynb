{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Diffusion Model Fundamentals\n",
    "\n",
    "**From Noise to Images: Understanding the Core of Modern AI Art**\n",
    "\n",
    "---\n",
    "\n",
    "Diffusion models are the backbone of the most powerful image generation systems today -- **Stable Diffusion**, **DALL-E 3**, **Midjourney**, and **FLUX**. Rather than generating images in a single forward pass (like GANs), diffusion models work by *learning to reverse a gradual noising process*.\n",
    "\n",
    "This notebook covers the mathematical and intuitive fundamentals:\n",
    "\n",
    "1. The forward and reverse diffusion processes\n",
    "2. Noise schedules and why they matter\n",
    "3. The training objective (epsilon prediction)\n",
    "4. Sampling algorithms -- from 1000-step DDPM to 4-step Flow Matching\n",
    "\n",
    "**Requirements**: Only `numpy` and `matplotlib` -- no GPU needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What Is a Diffusion Model?\n",
    "\n",
    "A diffusion model defines two complementary processes:\n",
    "\n",
    "### Forward Process $q$ (Noising)\n",
    "\n",
    "Gradually add **Gaussian noise** to real data $x_0$ over $T$ timesteps until the result is indistinguishable from pure random noise. Each step is a small perturbation:\n",
    "\n",
    "$$q(x_t \\mid x_{t-1}) = \\mathcal{N}\\!\\left(x_t;\\ \\sqrt{1 - \\beta_t}\\, x_{t-1},\\ \\beta_t \\mathbf{I}\\right)$$\n",
    "\n",
    "where $\\beta_t$ is a small variance that increases over time. Thanks to the reparameterization trick, we can jump directly to any timestep $t$:\n",
    "\n",
    "$$q(x_t \\mid x_0) = \\mathcal{N}\\!\\left(x_t;\\ \\sqrt{\\bar{\\alpha}_t}\\, x_0,\\ (1 - \\bar{\\alpha}_t)\\mathbf{I}\\right) \\qquad \\text{where } \\bar{\\alpha}_t = \\prod_{s=1}^{t}(1 - \\beta_s)$$\n",
    "\n",
    "### Reverse Process $p_\\theta$ (Denoising)\n",
    "\n",
    "A neural network learns to **reverse** each noising step, recovering the original data from pure noise:\n",
    "\n",
    "$$p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}\\!\\left(x_{t-1};\\ \\mu_\\theta(x_t, t),\\ \\Sigma_\\theta(x_t, t)\\right)$$\n",
    "\n",
    "### Intuition\n",
    "\n",
    "> **Analogy**: Imagine a photograph that has been progressively damaged -- first a little static, then more, until it is pure snow. The forward process *is* that progressive damage. The reverse process is a neural network that has studied millions of photos and learned, step by step, how to *restore* the image at every level of damage.\n",
    "\n",
    "| Forward Process | Reverse Process |\n",
    "|---|---|\n",
    "| Fixed (no learnable parameters) | Learned by the neural network |\n",
    "| Adds noise according to schedule $\\beta_t$ | Predicts and removes noise |\n",
    "| $x_0 \\rightarrow x_1 \\rightarrow \\cdots \\rightarrow x_T \\sim \\mathcal{N}(0, \\mathbf{I})$ | $x_T \\rightarrow x_{T-1} \\rightarrow \\cdots \\rightarrow x_0$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ── Create a synthetic \"image\" (colorful gradient pattern) ──────────────────\n",
    "def create_sample_image(size=128):\n",
    "    \"\"\"Create a colorful gradient pattern as our sample image.\"\"\"\n",
    "    x = np.linspace(0, 1, size)\n",
    "    y = np.linspace(0, 1, size)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    r = np.sin(2 * np.pi * xx) * 0.5 + 0.5\n",
    "    g = np.cos(2 * np.pi * yy) * 0.5 + 0.5\n",
    "    b = np.sin(2 * np.pi * (xx + yy)) * 0.5 + 0.5\n",
    "    return np.stack([r, g, b], axis=-1)\n",
    "\n",
    "image = create_sample_image()\n",
    "\n",
    "# ── Define a linear noise schedule ─────────────────────────────────────────\n",
    "T = 1000\n",
    "betas = np.linspace(1e-4, 0.02, T)\n",
    "alphas = 1 - betas\n",
    "alpha_cumprod = np.cumprod(alphas)\n",
    "\n",
    "# ── Visualize progressive noising at selected timesteps ───────────────────\n",
    "timesteps = [0, 100, 250, 500, 750, 999]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(timesteps), figsize=(18, 3.2))\n",
    "np.random.seed(0)\n",
    "\n",
    "for i, t in enumerate(timesteps):\n",
    "    sqrt_alpha = np.sqrt(alpha_cumprod[t])\n",
    "    sqrt_one_minus_alpha = np.sqrt(1 - alpha_cumprod[t])\n",
    "    noise = np.random.randn(*image.shape)\n",
    "    noisy = sqrt_alpha * image + sqrt_one_minus_alpha * noise\n",
    "    noisy = np.clip(noisy, 0, 1)\n",
    "\n",
    "    axes[i].imshow(noisy)\n",
    "    signal_pct = alpha_cumprod[t] * 100\n",
    "    axes[i].set_title(\n",
    "        f't = {t}\\n$\\\\bar{{\\\\alpha}}_t$ = {alpha_cumprod[t]:.3f} ({signal_pct:.0f}% signal)',\n",
    "        fontsize=10\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Forward Diffusion Process: Gradually Adding Noise',\n",
    "    fontsize=14, fontweight='bold', y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Noise Schedules\n",
    "\n",
    "The **noise schedule** $\\{\\beta_t\\}_{t=1}^{T}$ controls how quickly information is destroyed during the forward process. It is one of the most important design choices in a diffusion model.\n",
    "\n",
    "### Linear Schedule (DDPM, Ho et al. 2020)\n",
    "\n",
    "$\\beta_t$ increases linearly from $\\beta_1 = 10^{-4}$ to $\\beta_T = 0.02$. Simple and effective, but destroys too much information in the early timesteps, which can hurt generation quality.\n",
    "\n",
    "### Cosine Schedule (Nichol & Dhariwal, 2021)\n",
    "\n",
    "Designed so that $\\bar{\\alpha}_t$ follows a cosine curve, providing **smoother degradation**. The signal is preserved longer in the early steps and decays more gracefully:\n",
    "\n",
    "$$\\bar{\\alpha}_t = \\frac{f(t)}{f(0)}, \\qquad f(t) = \\cos\\!\\left(\\frac{t/T + s}{1 + s} \\cdot \\frac{\\pi}{2}\\right)^{\\!2}$$\n",
    "\n",
    "where $s = 0.008$ is a small offset to prevent $\\beta_t$ from being too small near $t = 0$.\n",
    "\n",
    "### Why It Matters\n",
    "\n",
    "- A schedule that destroys information **too quickly** wastes timestep budget on near-pure noise.\n",
    "- A schedule that is **too slow** requires more steps and compute.\n",
    "- The cosine schedule achieves better FID scores because it spends more timesteps in the perceptually meaningful mid-noise range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "t = np.arange(T)\n",
    "\n",
    "# ── Linear schedule ────────────────────────────────────────────────────────\n",
    "betas_linear = np.linspace(1e-4, 0.02, T)\n",
    "alphas_linear = 1 - betas_linear\n",
    "alpha_cumprod_linear = np.cumprod(alphas_linear)\n",
    "\n",
    "# ── Cosine schedule ────────────────────────────────────────────────────────\n",
    "def cosine_schedule(T, s=0.008):\n",
    "    \"\"\"Cosine noise schedule (Nichol & Dhariwal, 2021).\"\"\"\n",
    "    steps = np.arange(T + 1)\n",
    "    f = np.cos((steps / T + s) / (1 + s) * np.pi / 2) ** 2\n",
    "    alphas_cumprod = f / f[0]\n",
    "    betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]\n",
    "    return np.clip(betas, 0, 0.999), alphas_cumprod[1:]\n",
    "\n",
    "betas_cosine, alpha_cumprod_cosine = cosine_schedule(T)\n",
    "\n",
    "# ── Plot comparison ────────────────────────────────────────────────────────\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: beta_t\n",
    "ax1.plot(t, betas_linear, label='Linear', linewidth=2, color='#2196F3')\n",
    "ax1.plot(t, betas_cosine, label='Cosine', linewidth=2, color='#FF5722')\n",
    "ax1.set_xlabel('Timestep $t$', fontsize=12)\n",
    "ax1.set_ylabel('$\\\\beta_t$', fontsize=12)\n",
    "ax1.set_title('Noise Schedule: $\\\\beta_t$ over Time', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: cumulative alpha\n",
    "ax2.plot(t, alpha_cumprod_linear, label='Linear', linewidth=2, color='#2196F3')\n",
    "ax2.plot(t, alpha_cumprod_cosine, label='Cosine', linewidth=2, color='#FF5722')\n",
    "ax2.set_xlabel('Timestep $t$', fontsize=12)\n",
    "ax2.set_ylabel('$\\\\bar{\\\\alpha}_t$ (cumulative product)', fontsize=12)\n",
    "ax2.set_title('Signal Retention: $\\\\bar{\\\\alpha}_t$ over Time', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate the key difference\n",
    "ax2.annotate(\n",
    "    'Cosine preserves\\nmore signal early on',\n",
    "    xy=(200, alpha_cumprod_cosine[200]), xytext=(350, 0.85),\n",
    "    arrowprops=dict(arrowstyle='->', color='#FF5722', lw=1.5),\n",
    "    fontsize=10, color='#FF5722', fontweight='bold'\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    'Linear vs Cosine Noise Schedules',\n",
    "    fontsize=14, fontweight='bold', y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Training Objective\n",
    "\n",
    "### Epsilon Prediction (DDPM Loss)\n",
    "\n",
    "Instead of predicting the clean image $x_0$ directly, the network predicts the **noise** $\\epsilon$ that was added. The loss is a simple mean squared error:\n",
    "\n",
    "$$\\mathcal{L} = \\mathbb{E}_{x_0,\\, t,\\, \\epsilon}\\!\\left[\\left\\| \\epsilon - \\epsilon_\\theta(x_t, t) \\right\\|^2\\right]$$\n",
    "\n",
    "### Training Loop (simplified)\n",
    "\n",
    "```\n",
    "repeat:\n",
    "    1. Sample x_0 from the training data\n",
    "    2. Sample t ~ Uniform({1, ..., T})\n",
    "    3. Sample noise: epsilon ~ N(0, I)\n",
    "    4. Compute noisy image: x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * epsilon\n",
    "    5. Predict noise: epsilon_hat = model(x_t, t)\n",
    "    6. Compute loss: L = MSE(epsilon, epsilon_hat)\n",
    "    7. Backpropagate and update model weights\n",
    "```\n",
    "\n",
    "### Why Predict Noise Instead of the Image?\n",
    "\n",
    "- **Numerically stable**: Noise is zero-mean and unit-variance regardless of timestep.\n",
    "- **Equivalent formulations**: Predicting $\\epsilon$ is mathematically equivalent to predicting $x_0$ or the score $\\nabla_{x_t} \\log q(x_t)$ -- but epsilon prediction trains most reliably in practice.\n",
    "- **Connection to score matching**: $\\epsilon_\\theta \\approx -\\sqrt{1 - \\bar{\\alpha}_t}\\, \\nabla_{x_t} \\log q(x_t \\mid x_0)$, linking diffusion models to score-based generative models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Training Loop Diagram ──────────────────────────────────────────────────\n",
    "# Visualize the DDPM training pipeline as a flowchart using matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 7)\n",
    "ax.axis('off')\n",
    "\n",
    "# ── Style constants ────────────────────────────────────────────────────────\n",
    "box_color = '#E3F2FD'\n",
    "box_edge = '#1565C0'\n",
    "highlight_color = '#FFF3E0'\n",
    "highlight_edge = '#E65100'\n",
    "arrow_color = '#37474F'\n",
    "text_color = '#212121'\n",
    "\n",
    "def draw_box(ax, x, y, w, h, text, color=box_color, edge=box_edge, fontsize=10):\n",
    "    \"\"\"Draw a rounded rectangle with centered text.\"\"\"\n",
    "    from matplotlib.patches import FancyBboxPatch\n",
    "    box = FancyBboxPatch(\n",
    "        (x - w/2, y - h/2), w, h,\n",
    "        boxstyle='round,pad=0.15', facecolor=color,\n",
    "        edgecolor=edge, linewidth=2\n",
    "    )\n",
    "    ax.add_patch(box)\n",
    "    ax.text(x, y, text, ha='center', va='center', fontsize=fontsize,\n",
    "            color=text_color, fontweight='bold', wrap=True)\n",
    "\n",
    "def draw_arrow(ax, x1, y1, x2, y2):\n",
    "    \"\"\"Draw an arrow between two points.\"\"\"\n",
    "    ax.annotate(\n",
    "        '', xy=(x2, y2), xytext=(x1, y1),\n",
    "        arrowprops=dict(\n",
    "            arrowstyle='->', color=arrow_color,\n",
    "            lw=2, connectionstyle='arc3,rad=0'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ── Title ───────────────────────────────────────────────────────────────────\n",
    "ax.text(7, 6.6, 'DDPM Training Loop', ha='center', fontsize=16,\n",
    "        fontweight='bold', color='#0D47A1')\n",
    "\n",
    "# ── Row 1: Inputs ──────────────────────────────────────────────────────────\n",
    "draw_box(ax, 2.5, 5.5, 3.2, 0.7, '1. Sample $x_0$ from data')\n",
    "draw_box(ax, 7.0, 5.5, 3.2, 0.7, '2. Sample $t \\\\sim U\\\\{1..T\\\\}$')\n",
    "draw_box(ax, 11.5, 5.5, 3.2, 0.7, '3. Sample $\\\\epsilon \\\\sim \\\\mathcal{N}(0, I)$')\n",
    "\n",
    "# ── Arrows down ────────────────────────────────────────────────────────────\n",
    "draw_arrow(ax, 2.5, 5.1, 7.0, 4.35)\n",
    "draw_arrow(ax, 7.0, 5.1, 7.0, 4.35)\n",
    "draw_arrow(ax, 11.5, 5.1, 7.0, 4.35)\n",
    "\n",
    "# ── Row 2: Compute noisy image ─────────────────────────────────────────────\n",
    "draw_box(ax, 7.0, 4.0, 8.5, 0.7,\n",
    "         '4. Compute $x_t = \\\\sqrt{\\\\bar{\\\\alpha}_t}\\\\, x_0 '\n",
    "         '+ \\\\sqrt{1 - \\\\bar{\\\\alpha}_t}\\\\, \\\\epsilon$',\n",
    "         fontsize=11)\n",
    "\n",
    "draw_arrow(ax, 7.0, 3.6, 7.0, 2.85)\n",
    "\n",
    "# ── Row 3: Network prediction ──────────────────────────────────────────────\n",
    "draw_box(ax, 7.0, 2.5, 6.0, 0.7,\n",
    "         '5. Predict $\\\\hat{\\\\epsilon} = \\\\epsilon_\\\\theta(x_t,\\\\, t)$',\n",
    "         color=highlight_color, edge=highlight_edge, fontsize=11)\n",
    "\n",
    "draw_arrow(ax, 7.0, 2.1, 7.0, 1.35)\n",
    "\n",
    "# ── Row 4: Loss & update ───────────────────────────────────────────────────\n",
    "draw_box(ax, 7.0, 1.0, 8.0, 0.7,\n",
    "         '6. Loss $\\\\mathcal{L} = \\\\|\\\\epsilon - \\\\hat{\\\\epsilon}\\\\|^2$'\n",
    "         '        7. Backprop & update $\\\\theta$',\n",
    "         color='#E8F5E9', edge='#2E7D32', fontsize=11)\n",
    "\n",
    "# ── Loop-back arrow ────────────────────────────────────────────────────────\n",
    "ax.annotate(\n",
    "    '', xy=(0.5, 5.5), xytext=(0.5, 1.0),\n",
    "    arrowprops=dict(\n",
    "        arrowstyle='->', color='#B71C1C', lw=2.5,\n",
    "        connectionstyle='arc3,rad=0'\n",
    "    )\n",
    ")\n",
    "ax.text(0.3, 3.25, 'repeat', rotation=90, ha='center', va='center',\n",
    "        fontsize=11, fontweight='bold', color='#B71C1C')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sampling Algorithms\n",
    "\n",
    "Once the model is trained, we generate images by running the **reverse process** -- starting from pure noise $x_T \\sim \\mathcal{N}(0, \\mathbf{I})$ and iteratively denoising.\n",
    "\n",
    "The choice of **sampler** controls the trade-off between quality and speed:\n",
    "\n",
    "| Sampler | Steps | Type | Key Idea |\n",
    "|---------|-------|------|----------|\n",
    "| **DDPM** (Ho et al., 2020) | 1000 | Stochastic | Original formulation; faithful but slow |\n",
    "| **DDIM** (Song et al., 2020) | 50--100 | Deterministic | Reinterprets diffusion as an ODE; skip steps |\n",
    "| **Euler** | 20--50 | ODE solver | Simple first-order discretization |\n",
    "| **DPM-Solver** (Lu et al., 2022) | 20--25 | Higher-order ODE | Exponential integrator; fast convergence |\n",
    "| **Flow Matching** (Lipman et al., 2023) | 4--28 | ODE / straight paths | Used by SD3 and FLUX; linear trajectories |\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "Modern architectures like **Stable Diffusion 3** and **FLUX** use **Flow Matching** (also called Rectified Flows), which learns *straight-line* trajectories from noise to data. Because the paths are straighter, fewer discretization steps are needed -- achieving high quality in as few as **4 steps**.\n",
    "\n",
    "This is a paradigm shift: early diffusion models needed 1000 steps; state-of-the-art models now need fewer than 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Sampling Strategies: 1-D denoising trajectories ────────────────────────\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def simulate_denoising(n_steps, noise_start=3.0, target=1.0):\n",
    "    \"\"\"Simulate a 1-D denoising trajectory from noise to a target value.\"\"\"\n",
    "    trajectory = [noise_start]\n",
    "    for i in range(n_steps):\n",
    "        progress = (i + 1) / n_steps\n",
    "        current = trajectory[-1]\n",
    "        remaining = n_steps - i\n",
    "        step = (target - current) / remaining\n",
    "        noise = np.random.randn() * (1 - progress) * 0.5\n",
    "        trajectory.append(current + step + noise)\n",
    "    return np.array(trajectory)\n",
    "\n",
    "samplers = {\n",
    "    'DDPM (1000 steps)': 1000,\n",
    "    'DDIM (50 steps)': 50,\n",
    "    'Euler (20 steps)': 20,\n",
    "    'FLUX Flow Matching (4 steps)': 4,\n",
    "}\n",
    "\n",
    "colors = ['#1565C0', '#2E7D32', '#E65100', '#6A1B9A']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (name, steps), color in zip(axes, samplers.items(), colors):\n",
    "    trajectory = simulate_denoising(steps)\n",
    "    x_axis = np.linspace(0, 1, len(trajectory))  # normalize to [0, 1]\n",
    "\n",
    "    marker = 'o' if steps <= 50 else ''\n",
    "    ms = max(2, 10 - steps // 10)\n",
    "\n",
    "    ax.plot(x_axis, trajectory, color=color, marker=marker,\n",
    "            markersize=ms, alpha=0.8, linewidth=2)\n",
    "    ax.axhline(y=1.0, color='#D32F2F', linestyle='--', alpha=0.6,\n",
    "               label='Target signal', linewidth=1.5)\n",
    "    ax.fill_between(x_axis, trajectory, 1.0, alpha=0.07, color=color)\n",
    "\n",
    "    ax.set_title(name, fontsize=13, fontweight='bold', color=color)\n",
    "    ax.set_xlabel('Progress (0 = pure noise, 1 = final)', fontsize=10)\n",
    "    ax.set_ylabel('Value', fontsize=10)\n",
    "    ax.legend(fontsize=9, loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(-0.5, 4.0)\n",
    "\n",
    "plt.suptitle(\n",
    "    'Reverse Process: Different Sampling Strategies',\n",
    "    fontsize=14, fontweight='bold', y=1.01\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "<div style=\"background-color: #E3F2FD; padding: 20px; border-radius: 10px; border-left: 5px solid #1565C0;\">\n",
    "\n",
    "1. **Diffusion models learn to reverse a noising process** -- the forward process destroys information by adding Gaussian noise; the reverse process (a neural network) learns to reconstruct it.\n",
    "\n",
    "2. **The noise schedule controls the speed of information destruction.** Cosine schedules outperform linear schedules by preserving perceptually meaningful signal longer.\n",
    "\n",
    "3. **The training objective is simple**: predict the noise $\\epsilon$ that was added, then minimize MSE. This is equivalent to score matching.\n",
    "\n",
    "4. **Modern samplers dramatically reduce the number of steps needed.** From 1000 steps (DDPM) to 4 steps (Flow Matching in FLUX) -- a 250x speedup.\n",
    "\n",
    "5. **Next notebook**: How the neural network architecture evolved -- from the original **UNet** to **DiT** (Diffusion Transformer) to **MMDiT** (used in SD3 and FLUX).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. **Ho, J., Jain, A., & Abbeel, P.** (2020). *Denoising Diffusion Probabilistic Models*. NeurIPS 2020. [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)\n",
    "\n",
    "2. **Song, J., Meng, C., & Ermon, S.** (2020). *Denoising Diffusion Implicit Models*. ICLR 2021. [arXiv:2010.02502](https://arxiv.org/abs/2010.02502)\n",
    "\n",
    "3. **Nichol, A. Q. & Dhariwal, P.** (2021). *Improved Denoising Diffusion Probabilistic Models*. ICML 2021. [arXiv:2102.09672](https://arxiv.org/abs/2102.09672)\n",
    "\n",
    "4. **Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., & Zhu, J.** (2022). *DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling*. NeurIPS 2022. [arXiv:2206.00927](https://arxiv.org/abs/2206.00927)\n",
    "\n",
    "5. **Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., & Le, M.** (2023). *Flow Matching for Generative Modeling*. ICLR 2023. [arXiv:2210.02747](https://arxiv.org/abs/2210.02747)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
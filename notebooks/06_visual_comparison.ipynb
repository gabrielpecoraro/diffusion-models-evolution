{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visual Comparison: SD3 Medium vs FLUX.1-schnell\n",
    "**Head-to-Head on Identical Prompts \u2014 The 2024 Diffusion Model Showdown**\n",
    "\n",
    "This notebook generates the comparison grid for our README and LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"\"))\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from config.default import DiffusionConfig\n",
    "from models.memory_utils import setup_mps_environment, clear_memory, log_memory_usage\n",
    "from models.pipeline_factory import load_pipeline, generate_image\n",
    "from models.prompt_bank import BENCHMARK_PROMPTS\n",
    "\n",
    "os.makedirs(os.path.join(\"..\", \"outputs\", \"comparisons\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(\"..\", \"assets\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy: Sequential Model Loading on 16GB\n",
    "\n",
    "Since we only have 16GB of unified memory on Apple Silicon, we load models **sequentially** with aggressive memory cleanup between them. This ensures each model gets the full memory budget without OOM errors.\n",
    "\n",
    "- **SD3 Medium** runs first: 28 steps, float16, T5-XXL encoder dropped to save ~14GB\n",
    "- Memory is fully cleared (`del` pipeline + `gc.collect()` + `torch.mps.empty_cache()`)\n",
    "- **FLUX.1-schnell** runs second: 4 steps, GGUF Q4_K_S quantization (~4.5GB model weight)\n",
    "\n",
    "Same seed (42) and identical prompts ensure a fair apples-to-apples comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Phase 1: Generating with SD3 Medium\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sd3_config = DiffusionConfig(\n",
    "    model_name=\"sd3-medium\",\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=7.0,\n",
    "    height=512, width=512, seed=42,\n",
    "    dtype=\"float16\",\n",
    "    enable_cpu_offload=True,\n",
    "    drop_t5_encoder=True,\n",
    ")\n",
    "\n",
    "log_memory_usage(\"before SD3\")\n",
    "pipe_sd3 = load_pipeline(sd3_config)\n",
    "\n",
    "sd3_images = []\n",
    "sd3_times = []\n",
    "\n",
    "for i, ps in enumerate(BENCHMARK_PROMPTS):\n",
    "    print(f\"[SD3 {i+1}/{len(BENCHMARK_PROMPTS)}] {ps.prompt[:50]}...\")\n",
    "    sd3_config.prompt = ps.prompt\n",
    "    start = time.perf_counter()\n",
    "    img = generate_image(pipe_sd3, sd3_config)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    sd3_images.append(img)\n",
    "    sd3_times.append(elapsed)\n",
    "    print(f\"  {elapsed:.1f}s\")\n",
    "\n",
    "# Free SD3 completely\n",
    "del pipe_sd3\n",
    "clear_memory()\n",
    "log_memory_usage(\"after SD3 cleanup\")\n",
    "print(\"\\nSD3 Medium complete. Memory cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Phase 2: Generating with FLUX.1-schnell\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "flux_config = DiffusionConfig(\n",
    "    model_name=\"flux-schnell\",\n",
    "    quantization=\"Q4_K_S\",\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=0.0,\n",
    "    height=512, width=512, seed=42,\n",
    "    dtype=\"float16\",\n",
    "    enable_cpu_offload=True,\n",
    ")\n",
    "\n",
    "log_memory_usage(\"before FLUX\")\n",
    "pipe_flux = load_pipeline(flux_config)\n",
    "\n",
    "flux_images = []\n",
    "flux_times = []\n",
    "\n",
    "for i, ps in enumerate(BENCHMARK_PROMPTS):\n",
    "    print(f\"[FLUX {i+1}/{len(BENCHMARK_PROMPTS)}] {ps.prompt[:50]}...\")\n",
    "    flux_config.prompt = ps.prompt\n",
    "    start = time.perf_counter()\n",
    "    img = generate_image(pipe_flux, flux_config)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    flux_images.append(img)\n",
    "    flux_times.append(elapsed)\n",
    "    print(f\"  {elapsed:.1f}s\")\n",
    "\n",
    "del pipe_flux\n",
    "clear_memory()\n",
    "log_memory_usage(\"after FLUX cleanup\")\n",
    "print(\"\\nFLUX.1-schnell complete. Memory cleared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Comparison Grid\n",
    "\n",
    "Now we'll create a professional side-by-side comparison grid. This is the **hero image** for the README and LinkedIn post \u2014 SD3 Medium on the left, FLUX.1-schnell on the right, same prompts and seed throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prompts = len(BENCHMARK_PROMPTS)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 4 * n_prompts + 2))\n",
    "gs = gridspec.GridSpec(n_prompts + 1, 2, hspace=0.3, wspace=0.05,\n",
    "                        height_ratios=[0.3] + [1] * n_prompts)\n",
    "\n",
    "# Header row\n",
    "ax_header_left = fig.add_subplot(gs[0, 0])\n",
    "ax_header_left.text(0.5, 0.5, 'SD3 Medium\\n28 steps | float16 | no T5',\n",
    "                     ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "                     color='#1565C0',\n",
    "                     bbox=dict(boxstyle='round,pad=0.5', facecolor='#E3F2FD', edgecolor='#1565C0'))\n",
    "ax_header_left.axis('off')\n",
    "\n",
    "ax_header_right = fig.add_subplot(gs[0, 1])\n",
    "ax_header_right.text(0.5, 0.5, 'FLUX.1-schnell\\n4 steps | GGUF Q4_K_S',\n",
    "                      ha='center', va='center', fontsize=14, fontweight='bold',\n",
    "                      color='#C62828',\n",
    "                      bbox=dict(boxstyle='round,pad=0.5', facecolor='#FFEBEE', edgecolor='#C62828'))\n",
    "ax_header_right.axis('off')\n",
    "\n",
    "# Image rows\n",
    "for i in range(n_prompts):\n",
    "    # SD3 image\n",
    "    ax_sd3 = fig.add_subplot(gs[i + 1, 0])\n",
    "    ax_sd3.imshow(sd3_images[i])\n",
    "    ax_sd3.set_ylabel(f\"{BENCHMARK_PROMPTS[i].category.upper()}\\n{sd3_times[i]:.1f}s\",\n",
    "                       fontsize=10, fontweight='bold', rotation=0, labelpad=80, va='center')\n",
    "    ax_sd3.set_xticks([])\n",
    "    ax_sd3.set_yticks([])\n",
    "\n",
    "    # FLUX image\n",
    "    ax_flux = fig.add_subplot(gs[i + 1, 1])\n",
    "    ax_flux.imshow(flux_images[i])\n",
    "    ax_flux.set_ylabel(f\"{flux_times[i]:.1f}s\", fontsize=10, fontweight='bold',\n",
    "                        rotation=0, labelpad=30, va='center')\n",
    "    ax_flux.yaxis.set_label_position(\"right\")\n",
    "    ax_flux.set_xticks([])\n",
    "    ax_flux.set_yticks([])\n",
    "\n",
    "    # Add prompt as xlabel on the left image only\n",
    "    if i == n_prompts - 1:\n",
    "        ax_sd3.set_xlabel(\"\")\n",
    "        ax_flux.set_xlabel(\"\")\n",
    "\n",
    "fig.suptitle(\"Diffusion Models Evolution: SD3 Medium vs FLUX.1-schnell\\nSame prompts, same seed (42), 512\\u00d7512\",\n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# Save to assets\n",
    "comparison_path = os.path.join(\"..\", \"assets\", \"comparison_grid.png\")\n",
    "fig.savefig(comparison_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Saved comparison grid to {comparison_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"HEAD-TO-HEAD COMPARISON: SD3 Medium vs FLUX.1-schnell\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Prompt':<16} {'Category':<16} {'SD3 (s)':<10} {'FLUX (s)':<10} {'Speedup':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for ps, sd3_t, flux_t in zip(BENCHMARK_PROMPTS, sd3_times, flux_times):\n",
    "    speedup = sd3_t / flux_t if flux_t > 0 else float('inf')\n",
    "    print(f\"{ps.name:<16} {ps.category:<16} {sd3_t:<10.1f} {flux_t:<10.1f} {speedup:<10.1f}x\")\n",
    "\n",
    "avg_sd3 = sum(sd3_times) / len(sd3_times)\n",
    "avg_flux = sum(flux_times) / len(flux_times)\n",
    "avg_speedup = avg_sd3 / avg_flux if avg_flux > 0 else float('inf')\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'AVERAGE':<16} {'':<16} {avg_sd3:<10.1f} {avg_flux:<10.1f} {avg_speedup:<10.1f}x\")\n",
    "print()\n",
    "print(\"Configuration:\")\n",
    "print(f\"  SD3 Medium:     28 steps, guidance=7.0, float16, no T5-XXL\")\n",
    "print(f\"  FLUX.1-schnell: 4 steps, guidance=0.0, GGUF Q4_K_S\")\n",
    "print(f\"  Resolution:     512\\u00d7512\")\n",
    "print(f\"  Device:         Apple Silicon (16GB unified memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual side-by-side comparisons for each prompt\n",
    "for i, ps in enumerate(BENCHMARK_PROMPTS):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax1.imshow(sd3_images[i])\n",
    "    ax1.set_title(f\"SD3 Medium\\n{sd3_times[i]:.1f}s | 28 steps\", fontsize=11, fontweight='bold', color='#1565C0')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(flux_images[i])\n",
    "    ax2.set_title(f\"FLUX.1-schnell\\n{flux_times[i]:.1f}s | 4 steps\", fontsize=11, fontweight='bold', color='#C62828')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    fig.suptitle(f\"{ps.category.upper()}: {ps.prompt[:70]}...\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(\"..\", \"outputs\", \"comparisons\", f\"{ps.name}_comparison.png\"),\n",
    "                dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {len(BENCHMARK_PROMPTS)} individual comparisons to outputs/comparisons/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & Key Findings\n",
    "\n",
    "### Speed\n",
    "FLUX.1-schnell is dramatically faster despite having **6x more parameters** (12B vs 2B). The combination of guidance distillation and 4-step flow matching makes it possible to generate high-quality images in a fraction of the time SD3 Medium requires at 28 steps.\n",
    "\n",
    "### Text Rendering\n",
    "Both models benefit from MMDiT's two-way attention mechanism, which allows text tokens and image patches to attend to each other bidirectionally. FLUX tends to render clearer, more legible text \u2014 likely due to its larger parameter count and improved training data.\n",
    "\n",
    "### Photorealism\n",
    "FLUX.1 produces more photorealistic results even at 4-bit quantization (Q4_K_S). The flow matching objective and rectified flow paths give FLUX a smoother, more natural appearance compared to SD3's DDPM-based sampling.\n",
    "\n",
    "### Spatial Reasoning\n",
    "Both models handle spatial prompts well \u2014 understanding \"on top of\", \"behind\", and relative positioning. This is a major improvement over SDXL and earlier UNet-based architectures, where spatial compositionality was a persistent weakness.\n",
    "\n",
    "### The 2024 Takeaway\n",
    "The shift from **UNet to MMDiT** and **DDPM to Flow Matching** represents a genuine paradigm shift in generative AI. These are not incremental improvements \u2014 they fundamentally change how diffusion models understand and compose visual concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "Now that you've seen the comparison, try these:\n",
    "\n",
    "- **Run the interactive Gradio demo**: `python scripts/launch_app.py`\n",
    "- **Try your own prompts**: `python scripts/generate.py --model flux-schnell --prompt \"your prompt\"`\n",
    "- **Full benchmark**: `python scripts/benchmark.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}